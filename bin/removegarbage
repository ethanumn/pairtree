#!/usr/bin/env python3
import argparse
import numpy as np
import numpy.ma as ma
import json
import multiprocessing

import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'lib'))
import inputparser
import pairwise
import resultserializer
from common import Models, debug
import common

def _make_garb_logprior(garb_prior, S):
  assert 0 < garb_prior < 1
  #logprior = {'garbage': S*np.log(garb_prior), 'cocluster': -np.inf}
  # Scale prior with number of samples.
  logprior = {'garbage': S*np.log(garb_prior)}
  return logprior

def _calc_posterior(variants, garb_prior, parallel, pairwisefn=None):
  S = len(list(variants.values())[0]['var_reads'])
  logprior = _make_garb_logprior(garb_prior, S)

  if pairwisefn is None:
    results = None
  else:
    results = resultserializer.Results(pairwisefn)

  if results is not None and results.has_mutrel('evidence'):
    evidence = results.get_mutrel('evidence')
  else:
    _, evidence = pairwise.calc_posterior(variants, logprior, 'pairwise', parallel)
    if results is not None:
      results.add_mutrel('evidence', evidence)
      results.save()

  posterior = pairwise.make_full_posterior(evidence, logprior)
  return posterior

def _remove_garbage(posterior, max_garb_prob, seed):
  epsilon = common._EPSILON
  assert epsilon < max_garb_prob <= 1

  prob_garb = posterior.rels[:,:,Models.garbage]
  prob_garb = np.maximum(epsilon, prob_garb)
  logprob_garb = np.log(prob_garb)
  np.fill_diagonal(logprob_garb, 0.)

  debug('num_garb_pairs', np.sum(prob_garb >= max_garb_prob, axis=1))
  debug('total_loggarb', np.sum(logprob_garb, axis=1))

  nongarb = list(posterior.vids)
  garbage = set()
  worst_garb = np.max(prob_garb)

  while worst_garb > max_garb_prob:
    M = len(nongarb)
    assert M > 0
    assert logprob_garb.shape == (M,M)

    joint_garb = np.sum(logprob_garb, axis=1)
    worst = np.argmax(joint_garb)
    debug(
      'removing',
      nongarb[worst],
      joint_garb[worst],
      ','.join([nongarb[idx] for idx in range(M) if prob_garb[worst,idx] >= 0.5]),
      np.sort(prob_garb[worst])[-10:],
      np.sort(joint_garb)[-10:],
      worst_garb,
    )
    garbage.add(nongarb[worst])
    del nongarb[worst]

    for axis in (0,1):
      prob_garb = np.delete(prob_garb, worst, axis=axis)
      logprob_garb = np.delete(logprob_garb, worst, axis=axis)
    worst_garb = np.max(prob_garb)

  debug('worst', worst_garb)
  assert set(nongarb) | set(garbage) == set(posterior.vids)
  return common.sort_vids(garbage)

def main():
  parser = argparse.ArgumentParser(
    description='Detect garbage variants and produce a modified input that excludes them',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter
  )
  parser.add_argument('--seed', dest='seed', type=int,
    help='Integer seed used for pseudo-random number generator. Running with the same seed on the same inputs will produce exactly the same result.')
  parser.add_argument('--parallel', dest='parallel', type=int, default=None,
    help='Number of tasks to run in parallel. By default, this is set to the number of CPU cores on the system. On hyperthreaded systems, this will be twice the number of physical CPUs.')
  parser.add_argument('--prior', type=float, default=0.2, dest='garb_prior',
    help='Pairwise garbage prior probability. The default value of 0.2 represents a uniform prior over pairwise relationship types.')
  parser.add_argument('--max-garb-prob', type=float, default=0.01,
    help='Maximum probability of garbage to permit for any pair when the algorithm terminates.')
  parser.add_argument('--pairwise-results', dest='pairwise_results_fn',
    help='Filename to store pairwise evidence in, which allows you to try garbage removal with different parameters without having to repeat the pairwise computations.')
  parser.add_argument('--ignore-existing-garbage', action='store_true',
    help='Ignore any existing garbage variants listed in in_params_fn and test all variants. If not specified, any existing garbage variants will be kept as garbage and not tested again.')
  parser.add_argument('--verbose', action='store_true',
    help='Print debugging messages')
  parser.add_argument('ssm_fn',
    help='Input SSM file with mutations')
  parser.add_argument('in_params_fn',
    help='Input params file listing sample names and any existing garbage mutations')
  parser.add_argument('out_params_fn',
    help='Output params file with modified list of garbage mutations')
  args = parser.parse_args()

  common.debug.DEBUG = args.verbose

  # We don't currently use any PRNG functions, but seed it in case we do in the future.
  if args.seed is not None:
    seed = args.seed
  else:
    # Maximum seed is 2**32 - 1.
    seed = np.random.randint(2**32)
  np.random.seed(seed)

  np.set_printoptions(linewidth=400, precision=3, threshold=sys.maxsize, suppress=True)
  np.seterr(divide='raise', invalid='raise', over='raise')
  parallel = args.parallel if args.parallel is not None else multiprocessing.cpu_count()

  if args.ignore_existing_garbage:
    variants, params = inputparser.load_ssms_and_params(args.ssm_fn, args.in_params_fn, remove_garb=False)
    params['garbage'] = []
  else:
    variants, params = inputparser.load_ssms_and_params(args.ssm_fn, args.in_params_fn)

  posterior = _calc_posterior(variants, args.garb_prior, parallel, args.pairwise_results_fn)
  garbage_vids = _remove_garbage(
    posterior,
    args.max_garb_prob,
    seed,
  )

  debug(len(garbage_vids))
  debug(garbage_vids)
  debug(common.sort_vids(set(variants.keys()) - set(garbage_vids)))

  params['garbage'] = common.sort_vids(set(garbage_vids) | set(params['garbage']))
  with open(args.out_params_fn, 'w') as F:
    json.dump(params, F)

if __name__ == '__main__':
  # This is default on Unix but not macOS. Without this, resources aren't
  # inherited by subprocesses on macOS and various things break. However, on
  # macOS, it can cause crashes. See
  # https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
  # On top of this, MacOS throws an exception since set_start_method is called elsewhere, 
  # adding the argument 'force=True' resolves the exception.
  if sys.platform == "darwin":
    multiprocessing.set_start_method('fork', force=True)
  main()
